{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory Optimization (TO)\n",
    "\n",
    "In this notebook, we discuss an efficient numerical method for finding a dynamically feasible trajectory. Let us consider the discrete time optimal control problem (OCP):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\min_{x_{0:N},\\,u_{0:N-1}} &\\sum_{k=0}^{N-1} \\ell_k(x_k, u_k) + \\ell_N(x_N) \\\\\n",
    "    \\textrm{s.t.} \\quad &x_{k+1} = f(x_k, u_k) \\\\    \n",
    "    & x_k \\in \\mathcal{X}_k,\\; u_k \\in \\mathcal{U}_k.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In many applications, the systems are given in continuous time, in form of differential equations:\n",
    "$\n",
    "\\dot{x} = f_\\text{c}(x, u).\n",
    "$\n",
    "As a result, we need to solve the differential equation via numerical integration. In this notebook, we use the 4th-order explicit Rungeâ€“Kutta (RK4) method for integration, without delving into the specifics. For further details, readers are encouraged to refer to Chapter 8 of Rawlings's book. Additionally, for simplicity, we consider an unconstrained numerical OCP. Let us start to solve this problem. First, we treat the system dynamics as equality constraints and formulate the OCP as a nonlinear program\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\min_{\\boldsymbol{z}}\\; &f(\\boldsymbol{z}) \\\\\n",
    "    \\text{s.t.}\\; &h(\\boldsymbol{z}) = 0,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\boldsymbol{z} := \\left( x_0, u_0, x_1, u_1, \\dots, u_{N-1}, x_N \\right)$ represents the concatenated state trajectory and input sequence, and $h(\\boldsymbol{z})$ involves the stacked dynamics equations\n",
    "$$\n",
    "h(\\boldsymbol{z}) = \\begin{bmatrix}\n",
    "x_0 - \\hat{x} \\\\\n",
    "f(x_0, u_0) - x_1 \\\\\n",
    "f(x_1, u_1) - x_2 \\\\\n",
    "\\vdots \\\\\n",
    "f(x_{N-1}, u_{N-1}) - x_N\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "where $\\hat{x}$ is the initial state. \n",
    "\n",
    "## CasADi\n",
    "We now employ [CasADi](https://web.casadi.org/) to formulate the nonlinear program and solve the optimization problem using [IPOPT](http://cepac.cheme.cmu.edu/pasilectures/biegler/ipopt.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import casadi as ca\n",
    "import numpy as np\n",
    "\n",
    "dim_x = 4\n",
    "dim_u = 1\n",
    "\n",
    "q = ca.SX.sym('q', dim_x)\n",
    "u = ca.SX.sym('u', dim_u)\n",
    "\n",
    "# Define the cartpole continuous-time dynamics\n",
    "q1, q2, q3, q4 = ca.vertsplit(q, 1)\n",
    "\n",
    "# Parameters\n",
    "L=1.0 \n",
    "m1=1.0 \n",
    "m2=1.0 \n",
    "g=9.81\n",
    "\n",
    "q1_dot = q3\n",
    "q2_dot = q4\n",
    "q3_dot =  (L*m2*ca.sin(q2)*q4*q4 + u + m2*g*ca.cos(q2)*ca.sin(q2)) / (m1 + m2*(1-ca.cos(q2)**2))\n",
    "q4_dot = -(L*m2*ca.cos(q2)*ca.sin(q2)*q4*q4 + u*ca.cos(q2) + (m1+m2)*g*ca.sin(q2)) / (L*m1 + L*m2*(1-ca.cos(q2)**2))\n",
    "\n",
    "q_dot = ca.vertcat(q1_dot, q2_dot, q3_dot, q4_dot)\n",
    "fc_cartpole = ca.Function('fc_cartpole', [q, u], [q_dot])\n",
    "\n",
    "# RK4 integration\n",
    "dt = 0.05\n",
    "k1 = fc_cartpole(q, u)\n",
    "k2 = fc_cartpole(q + dt/2*k1, u)\n",
    "k3 = fc_cartpole(q + dt/2*k2, u)\n",
    "k4 = fc_cartpole(q + dt*k3, u)\n",
    "q_next = q + dt/6*(k1 + 2*k2 + 2*k3 + k4)\n",
    "f_rk4_cartpole = ca.Function('f_rk4_cartpole', [q, u], [q_next])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_TO_ca(x0, N, dt, x_ref, u_ref):\n",
    "    # Cost weights\n",
    "    Q = np.diag([1, 20, 1, 1])\n",
    "    R = np.array([[0.25]])\n",
    "    Qf = 20 * Q\n",
    "    \n",
    "    # Define the state and control decision variables\n",
    "    X = ca.SX.sym('x', dim_x, N + 1)\n",
    "    U = ca.SX.sym('u', dim_u, N)\n",
    "        \n",
    "    # Quadratic cost function\n",
    "    cost = 0.\n",
    "    for k in range(N):\n",
    "        x_err = X[:,k] - x_ref\n",
    "        u_err = U[:,k] - u_ref \n",
    "        cost += ca.mtimes([x_err.T, Q, x_err]) + ca.mtimes([u_err.T, R, u_err])\n",
    "    # Terminal cost\n",
    "    x_err = X[:,-1] - x_ref\n",
    "    cost += ca.mtimes([x_err.T, Qf, x_err])\n",
    "    \n",
    "    # Dynamics constraints\n",
    "    g_dyn = [X[:,0] - x0]\n",
    "    # RK4 integration\n",
    "    for k in range(N):\n",
    "        x_k = X[:,k]\n",
    "        u_k = U[:,k]\n",
    "        # RK4 step\n",
    "        # k1 = fc_cartpole(x_k, u_k)\n",
    "        # k2 = fc_cartpole(x_k + dt / 2 * k1, u_k)\n",
    "        # k3 = fc_cartpole(x_k + dt / 2 * k2, u_k)\n",
    "        # k4 = fc_cartpole(x_k + dt * k3, u_k)\n",
    "        # x_next = x_k + dt / 6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "        x_next = f_rk4_cartpole(x_k, u_k)\n",
    "        g_dyn.append(x_next - X[:,k+1])\n",
    "        \n",
    "    # Concatenate constraints\n",
    "    g = ca.vertcat(*g_dyn)\n",
    "    g_min = 0.\n",
    "    g_max = 0.\n",
    "    \n",
    "    # Stack up the decision variables\n",
    "    w = ca.vertcat(ca.reshape(X, -1, 1), ca.reshape(U, -1, 1))\n",
    "    # Here, you can set bounds on states and controls if necessary\n",
    "    # For simplicity, we assume no bounds (can be modified as needed)\n",
    "    w_min = -ca.inf\n",
    "    w_max =  ca.inf\n",
    "    \n",
    "    # Create the NLP problem\n",
    "    nlp = {'x': w, 'f': cost, 'g': g}\n",
    "    # Create the solver instance\n",
    "    solver = ca.nlpsol('solver', 'ipopt', nlp, \n",
    "                       {'ipopt': {'print_level': 5}} # Specify the solver options \n",
    "    ) \n",
    "    \n",
    "    X_init = np.zeros((dim_x, N + 1))\n",
    "    U_init = np.zeros((dim_u, N))\n",
    "    w_init = ca.vertcat(X_init.reshape((-1, 1)), U_init.reshape((-1, 1)))\n",
    "    \n",
    "    # Solve the NLP\n",
    "    solution = solver(x0=w_init, lbx=w_min, ubx=w_max, lbg=g_min, ubg=g_max)\n",
    "    \n",
    "    # Extract the solution\n",
    "    w_opt = solution['x']\n",
    "    X_opt = w_opt[:dim_x * (N + 1)].reshape((dim_x, N + 1)).full()\n",
    "    U_opt = w_opt[dim_x * (N + 1):].reshape((dim_u, N)).full()\n",
    "    \n",
    "    return X_opt, U_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "dt = 0.05\n",
    "x_ref = np.array([0, np.pi, 0, 0])\n",
    "u_ref = np.array([0])\n",
    "x0 = np.array([0, 0, 0, 0])\n",
    "\n",
    "X_opt_ca, U_opt_ca = solve_TO_ca(x0, N, dt, x_ref, u_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time = np.arange(N + 1) * dt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axs[0, 0].plot(time, X_opt_ca[0,:])\n",
    "axs[0, 0].set(ylabel='q1 [m]')\n",
    "axs[0, 0].grid()\n",
    "\n",
    "axs[0, 1].plot(time, np.rad2deg(X_opt_ca[1,:]))\n",
    "axs[0, 1].set(ylabel='q2 [deg]')\n",
    "axs[0, 1].grid()\n",
    "\n",
    "axs[1, 0].plot(time, X_opt_ca[2,:])\n",
    "axs[1, 0].set(xlabel='Time [s]', ylabel='q3 [m/s]')\n",
    "axs[1, 0].grid()\n",
    "\n",
    "axs[1, 1].plot(time, X_opt_ca[3,:])\n",
    "axs[1, 1].set(xlabel='Time [s]', ylabel='q4 [rad/s]')\n",
    "axs[1, 1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative LQR (iLQR)\n",
    "\n",
    "We have solved the TO problem with the help of CasADi. Next, we develop our own TO solver from the perspective of optimization. We begin by writing down the Lagrangian function\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathcal{L}(\\boldsymbol{z}, \\boldsymbol{\\lambda}) &= \\lambda_0^\\top (\\hat{x}_0 - x_0) + \n",
    "    \\sum_{k=0}^{N-1} \\left( \\ell_k(x_k, u_{k}) + \\lambda_{k+1}^\\top \\left(f(x_{k}, u_{k}) - x_{k+1} \\right)\\right) + \\ell_N(x_N),\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\boldsymbol{\\lambda} := (\\lambda_0, \\dots, \\lambda_N)$ is a collection of Lagrange multipliers associated with dynamics constraints.\n",
    "The first-order optimality condition is given by\n",
    "$$\n",
    "\\frac{\\partial\\mathcal{L}}{\\partial x_{0:N}} = 0, \\quad \\frac{\\partial\\mathcal{L}}{\\partial u_{0:N-1}} = 0, \\quad  \\frac{\\partial\\mathcal{L}}{\\partial \\lambda_{0:N}} = 0.\n",
    "$$\n",
    "\n",
    "For notational simplicity, we denote stage cost gradients $\\nabla_x \\ell_k$ and $\\nabla_u \\ell_k$ as $\\ell_{x, k}$ and $\\ell_{u, k}$, respectively. The Jacobian matrices of the dynamics are represented by $f_{x, k}$ and $f_{u, k}$.\n",
    "Let us delve into the optimality condition.\n",
    "\n",
    "For $k = 0$, we have\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    0 &= \\ell_{x, 0} + f_{x, 0}^\\top \\lambda_{1} - \\lambda_{0}, \\\\\n",
    "    0 &= \\ell_{u, 0} + f_{u, 0}^\\top \\lambda_{1}, \\\\\n",
    "    0 &= \\hat{x}_0 - x_{0}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For $0 < k <= N-1$, we have\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    0 &= \\ell_{x, k} + f_{x, k}^\\top \\lambda_{k+1} - \\lambda_{k}, \\\\\n",
    "    0 &= \\ell_{u, k} + f_{u, k}^\\top \\lambda_{k+1}, \\\\\n",
    "    0 &= f(x_{k-1}, u_{k-1}) - x_{k}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For $k = N$, we have\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 &= \\ell_{x, N} - \\lambda_{N}, \\\\\n",
    "0 &= f(x_{N-1}, u_{N-1}) - x_{N}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Collecting all equations, we obtain\n",
    "$$\n",
    "F(\\boldsymbol{z}, \\boldsymbol{\\lambda}) = \n",
    "\\begin{bmatrix}\n",
    "    \\ell_{x, 0} + f_{x, 0}^\\top \\lambda_{1} - \\lambda_{0} \\\\\n",
    "    \\ell_{u, 0} + f_{u, 0}^\\top \\lambda_{1} \\\\\n",
    "    \\hat{x}_0 - x_{0} \\\\\n",
    "    \\ell_{x, 1} + f_{x, 1}^\\top \\lambda_{2} - \\lambda_{1} \\\\\n",
    "    \\ell_{u, 1} + f_{u, 1}^\\top \\lambda_{2} \\\\\n",
    "    f(x_{0}, u_{0}) - x_{1} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\ell_{x, N} - \\lambda_{N} \\\\\n",
    "    f(x_{N-1}, u_{N-1}) - x_{N}\n",
    "\\end{bmatrix} = 0\n",
    "$$\n",
    "\n",
    "This becomes a root-finding problem. We apply a Newton-type method to solve it. Each iteration involves solving the folowing linear system\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) + \\nabla_{\\boldsymbol{z}} F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) \\delta \\boldsymbol{z} + \n",
    "    \\nabla_{\\boldsymbol{\\lambda}} F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) (\\boldsymbol{\\lambda} - \\bar{\\boldsymbol{\\lambda}}) &= 0 \\\\\n",
    "    \\nabla_{\\boldsymbol{z}} F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) \\delta \\boldsymbol{z} + \n",
    "    \\nabla_{\\boldsymbol{\\lambda}} F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) \\boldsymbol{\\lambda}\n",
    "    &= -F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) + \n",
    "    \\nabla_{\\boldsymbol{\\lambda}} F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) \\bar{\\boldsymbol{\\lambda}},\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\delta \\boldsymbol{z} = \\boldsymbol{z} - \\bar{\\boldsymbol{z}}$, with $\\bar{\\boldsymbol{z}}$ and $\\bar{\\boldsymbol{\\lambda}}$ representing the nominal variables around which the root-finding problem is linearized. We derive other matrices as follows:\n",
    "$$\n",
    "\\nabla_{\\boldsymbol{z}} F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) = \n",
    "\\begin{bmatrix}\n",
    "    \\bar{Q}_0 & \\bar{S}_0^\\top \\\\\n",
    "    \\bar{S}_0 & \\bar{R}_0 \\\\\n",
    "    -I & 0 \\\\\n",
    "    & & \\bar{Q}_1 & \\bar{S}_1^\\top \\\\\n",
    "    & & \\bar{S}_1 & \\bar{R}_1 \\\\\n",
    "    A_0 & B_0 & -I \\\\\n",
    "    & & & & \\ddots \\\\\n",
    "    & & & & & P_N \\\\\n",
    "    & & & A_{N-1} & B_{N-1} & -I\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    \\bar{Q}_k & \\bar{S}_k^\\top \\\\\n",
    "    \\bar{S}_k & \\bar{R}_k \\\\\n",
    "\\end{bmatrix} = \\nabla^2_{x, u} \\left( \\ell_k(\\bar{x}_k, \\bar{u}_k) + \\bar{\\lambda}_{k+1}^\\top f(\\bar{x}_k, \\bar{u}_k) \\right) \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_{\\boldsymbol{\\lambda}} F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) = \n",
    "\\begin{bmatrix}\n",
    "-I & A_0^\\top \\\\\n",
    " & B_0^\\top \\\\\n",
    " 0 & 0  \\\\\n",
    " & -I & A_1^\\top \\\\\n",
    " &  & B_0^\\top \\\\\n",
    " 0 & 0 & 0 \\\\\n",
    " & & & \\ddots \\\\\n",
    " & & & & A_{N-1}^\\top \\\\\n",
    " & & & & B_{N-1}^\\top \\\\\n",
    " & & & & -I \\\\\n",
    " 0 & & \\cdots & & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "-F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) + \n",
    "    \\nabla_{\\boldsymbol{\\lambda}} F(\\bar{\\boldsymbol{z}}, \\bar{\\boldsymbol{\\lambda}}) \\bar{\\boldsymbol{\\lambda}} = \n",
    "\\begin{bmatrix}\n",
    "    -\\ell_{x, 0} (\\bar{x}_0, \\bar{u}_0) \\\\\n",
    "    -\\ell_{u, 0} (\\bar{x}_0, \\bar{u}_0) \\\\\n",
    "    \\hat{x}_0 - \\bar{x}_{0} \\\\\n",
    "    -\\ell_{x, 1} (\\bar{x}_1, \\bar{u}_1) \\\\\n",
    "    -\\ell_{u, 1} (\\bar{x}_1, \\bar{u}_1) \\\\\n",
    "    f(\\bar{x}_{1}, \\bar{u}_{1}) - \\bar{x}_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    -\\ell_{x, N} (\\bar{x}_N) \\\\\n",
    "    f(\\bar{x}_{N-1}, \\bar{u}_{N-1}) - \\bar{x}_{N}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<!-- $$\n",
    "\\boldsymbol{w} = (\\lambda_0, x_0, u_0, \\lambda_1, \\dots, \\lambda_N, x_N)\n",
    "$$ -->\n",
    "\n",
    "Stacking $\\delta \\boldsymbol{z}$ and $\\boldsymbol{\\lambda}$ in a specific order, we obtain the KKT systems for the optimization problem\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & -I \\\\\n",
    "-I & \\bar{Q}_0 & \\bar{S}_0^\\top & A_0^\\top \\\\\n",
    "& \\bar{S}_0 & \\bar{R}_0 & B_0^\\top \\\\\n",
    "& A_0 & B_0 & 0 & -I \\\\\n",
    "& & & -I & \\ddots \\\\\n",
    "& & & & & \\bar{Q}_{N-1} & \\bar{S}_{N-1}^\\top & A_{N-1}^\\top \\\\\n",
    "& & & & & \\bar{S}_{N-1} & \\bar{R}_{N-1} & B_{N-1}^\\top \\\\\n",
    "& & & & & A_{N-1} & B_{N-1} & 0 & -I \\\\\n",
    "& & & & & & & -I & P_N \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    \\lambda_0 \\\\\n",
    "    \\delta x_0 \\\\\n",
    "    \\delta u_0 \\\\\n",
    "    \\lambda_1 \\\\\n",
    "    \\delta x_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\delta x_{N-1} \\\\\n",
    "    \\delta u_{N-1} \\\\\n",
    "    \\lambda_{N} \\\\\n",
    "    \\delta x_N\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "    \\hat{x}_0 - \\bar{x}_{0} \\\\\n",
    "    -\\ell_{x, 0} (\\bar{x}_0, \\bar{u}_0) \\\\\n",
    "    -\\ell_{u, 0} (\\bar{x}_0, \\bar{u}_0) \\\\\n",
    "    f(\\bar{x}_{1}, \\bar{u}_{1}) - \\bar{x}_{2} \\\\\n",
    "    -\\ell_{x, 1} (\\bar{x}_1, \\bar{u}_1) \\\\\n",
    "    \\vdots \\\\\n",
    "    -\\ell_{x, N-1} (\\bar{x}_{N-1}, \\bar{u}_{N-1}) \\\\\n",
    "    -\\ell_{u, N-1} (\\bar{x}_{N-1}, \\bar{u}_{N-1}) \\\\\n",
    "    f(\\bar{x}_{N-1}, \\bar{u}_{N-1}) - \\bar{x}_{N} \\\\\n",
    "    -\\ell_{x, N} (\\bar{x}_N) \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In fact, the KKT system above is equivalent to the following LQR problem\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\min_{\\delta x, \\delta u} \\quad &\\sum_{k=0}^{N-1} \\begin{bmatrix} \\bar{q}_k \\\\ \\bar{r}_k \\end{bmatrix}^\\top  \\begin{bmatrix} \\delta x_k \\\\ \\delta u_k \\end{bmatrix} \n",
    "    + \\frac{1}{2} \\begin{bmatrix} \\delta x_k \\\\ \\delta u_k \\end{bmatrix}^\\top\n",
    "    \\begin{bmatrix} \\bar{Q}_k & \\bar{S}_k^\\top \\\\ \\bar{S}_k & \\bar{R}_k \\end{bmatrix} \n",
    "    \\begin{bmatrix} \\delta x_k \\\\ \\delta u_k \\end{bmatrix}  \n",
    "    + p_N^\\top \\delta x_N + \\frac{1}{2} \\delta x_N^T P_N \\delta x_N \\\\\n",
    "    \\text{s.t.}\\quad & \\delta x_{k+1} = A_k \\delta x_k + B_k \\delta u_k + c_k,\\; i = 0, \\dots, N-1,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where the linearized system is given by\n",
    "$$\n",
    "A_k = \\frac{\\partial f}{\\partial x} (\\bar{x}_k, \\bar{u}_k), \n",
    "\\quad B_k = \\frac{\\partial f}{\\partial u} (\\bar{x}_k, \\bar{u}_k),\n",
    "\\quad c_k = f (\\bar{x}_k, \\bar{u}_k) - A_k \\bar{x}_k - B_k \\bar{u}_k.\n",
    "$$\n",
    "\n",
    "The cost gradients are derived as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\bar{q}_k &= \\ell_{x, k} (\\bar{x}_i, \\bar{u}_i), \\\\\n",
    "\\bar{r}_k & = \\ell_{u, k} (\\bar{x}_i, \\bar{u}_i), \\\\\n",
    "p_N &= \\ell_{x, N} (\\bar{x}_N).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The Hessian for the terminal stage is \n",
    "$$\n",
    "P_N = \\nabla_{x}^2 \\ell(\\bar{x}_N).\n",
    "$$\n",
    "\n",
    "The exact Hessian blocks for the remaining stages are given by\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    \\bar{Q}_k & \\bar{S}_k^\\top \\\\\n",
    "    \\bar{S}_k & \\bar{R}_k \\\\\n",
    "\\end{bmatrix} = \\nabla^2_{x, u} \\left( \\ell_k(\\bar{x}_k, \\bar{u}_k) + \\bar{\\lambda}_{k+1}^\\top f(\\bar{x}_k, \\bar{u}_k) \\right).\n",
    "$$\n",
    "Since computing the exact Hessian can be challenging sometimes, it is common practice to omit \n",
    "$ \\bar{\\lambda}_{k+1}^\\top f(\\bar{x}_k, \\bar{u}_k) $, leading to  \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    \\bar{Q}_k & \\bar{S}_k^\\top \\\\\n",
    "    \\bar{S}_k & \\bar{R}_k \n",
    "\\end{bmatrix} = \\nabla^2_{x, u} \\ell_k(\\bar{x}_k, \\bar{u}_k).\n",
    "$$\n",
    "This is known as the generalized Gauss-Newton Hessian approximation. With such an approximation, we can solve the LQR problem using the Riccati recursion and perform a **nonlinear rollout** to recover the optimal state trajectory and input sequence. We then linearize the original problem around the optimal state trajectory and input sequence from the previous iteration, formulating a new LQR problem. This is known as **iLQR**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CasADi to compute linearized system matrices, $A_k$, $B_k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_dyn_q = ca.jacobian(q_next, q)\n",
    "jac_dyn_u = ca.jacobian(q_next, u)\n",
    "jac_dyn_q_fun = ca.Function('jac_dyn_q_fun', [q, u], [jac_dyn_q])\n",
    "jac_dyn_u_fun = ca.Function('jac_dyn_u_fun', [q, u], [jac_dyn_u])\n",
    "\n",
    "def get_dynamics_matrices(x, u):\n",
    "    A = jac_dyn_q_fun(x, u)\n",
    "    B = jac_dyn_u_fun(x, u)\n",
    "    return A.full(), B.full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def stage_cost(params, x, u, k):\n",
    "    Q = params.Q\n",
    "    R = params.R\n",
    "    dx = x - params.xf\n",
    "    du = u - params.uf  \n",
    "    return 0.5 * dx.T @ Q @ dx + 0.5 * du.T @ R @ du\n",
    "\n",
    "def final_cost(params, x):\n",
    "    N = params.N\n",
    "    Qf = params.Qf\n",
    "    dx = x - params.xf\n",
    "    return 0.5 * dx.T @ Qf @ dx\n",
    "\n",
    "def stage_cost_expansion(params, x, u, k):\n",
    "    Q = params.Q\n",
    "    R = params.R\n",
    "    dx = x - params.xf\n",
    "    du = u - params.uf \n",
    "    # l_xx, l_ux, l_uu, l_x, l_u\n",
    "    return deepcopy(Q), \\\n",
    "        np.zeros((R.shape[0], Q.shape[0])), \\\n",
    "        deepcopy(R), \\\n",
    "        Q @ dx, \\\n",
    "        R @ du\n",
    "\n",
    "def final_cost_expansion(params, x):\n",
    "    N = params.N\n",
    "    Qf = params.Qf\n",
    "    dx = x - params.xf\n",
    "    # lf_xx, lf_x\n",
    "    return deepcopy(Qf), \\\n",
    "        Qf @ dx\n",
    "\n",
    "def trajectory_cost(params, x_trj, u_trj):\n",
    "    N = params.N\n",
    "    cost = 0.\n",
    "    for k in range(N):\n",
    "        cost += stage_cost(params, x_trj[k, :], u_trj[k, :], k)\n",
    "    cost += final_cost(params, x_trj[N, :])\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import cho_factor, cho_solve\n",
    "\n",
    "def backward_pass(params, x_trj, u_trj, regu):\n",
    "    symmetrize = lambda x: (x + x.T) / 2   \n",
    "    N = params.N\n",
    "    dim_x = x_trj.shape[1]\n",
    "    dim_u = u_trj.shape[1]\n",
    "        \n",
    "    K_trj = np.zeros([N, dim_u, dim_x])\n",
    "    d_trj = np.zeros([N, dim_u])\n",
    "    expected_cost_redu = 0.\n",
    "\n",
    "    # final cost expansion\n",
    "    V_xx, V_x = final_cost_expansion(params, x_trj[N, :])\n",
    "\n",
    "    for k in range(N-1, -1, -1):\n",
    "        # dynamics jacobians\n",
    "        A, B = get_dynamics_matrices(x_trj[k, :], u_trj[k, :])\n",
    "\n",
    "        # stage cost expansion\n",
    "        l_xx, l_ux, l_uu, l_x, l_u = stage_cost_expansion(params, x_trj[k, :], u_trj[k, :], k)\n",
    "\n",
    "        # Q function expansion\n",
    "        Q_x  = l_x + A.T @ V_x\n",
    "        Q_u  = l_u + B.T @ V_x\n",
    "        Q_xx = l_xx + A.T @ V_xx @ A\n",
    "        Q_uu = l_uu + B.T @ V_xx @ B\n",
    "        Q_ux = l_ux + B.T @ V_xx @ A\n",
    "\n",
    "        # add regularization to ensure that Q_uu is invertible and well conditioned        \n",
    "        Q_uu_regu = Q_uu + np.eye(dim_u) * regu\n",
    "        Q_uu_regu = symmetrize(Q_uu_regu)\n",
    "\n",
    "        chofact = cho_factor(Q_uu_regu)\n",
    "        K = -cho_solve(chofact, Q_ux)\n",
    "        d = -cho_solve(chofact, Q_u)\n",
    "        K_trj[k, :, :] = K\n",
    "        d_trj[k, :]    = d\n",
    "        \n",
    "        # cost-to-go\n",
    "        V_xx = Q_xx + K.T @ Q_uu @ K + K.T @ Q_ux + Q_ux.T @ K\n",
    "        V_xx = symmetrize(V_xx)\n",
    "        V_x  = Q_x  + K.T @ Q_uu @ d + K.T @ Q_u  + Q_ux.T @ d\n",
    "\n",
    "        # expected cost reduction\n",
    "        expected_cost_redu += -Q_u.T @ d - 0.5 * d.T @ Q_uu @ d\n",
    "\n",
    "    return K_trj, d_trj, expected_cost_redu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(params, \n",
    "                 x_trj, u_trj, \n",
    "                 K_trj, d_trj, \n",
    "                 cost,\n",
    "                 f_dyn):\n",
    "    N = params.N\n",
    "    dim_x = x_trj.shape[1]\n",
    "    dim_u = u_trj.shape[1]\n",
    "    \n",
    "    x_trj_new = np.zeros((N + 1, dim_x))\n",
    "    x_trj_new[0, :] = x_trj[0, :]\n",
    "    u_trj_new = np.zeros((N, dim_u))\n",
    "    alpha = 1.\n",
    "    \n",
    "    # line search\n",
    "    for _ in range(params.max_ls_iter):\n",
    "        for k in range(N):\n",
    "            u_trj_new[k, :] = u_trj[k, :] + K_trj[k, :, :] @ (x_trj_new[k, :] - x_trj[k, :]) + alpha * d_trj[k, :]\n",
    "            x_trj_new[k+1, :] = f_dyn(x_trj_new[k, :], u_trj_new[k, :]).full().flatten()\n",
    "        cost_new = trajectory_cost(params, x_trj_new, u_trj_new)\n",
    "\n",
    "        if cost_new < cost:\n",
    "            return x_trj_new, u_trj_new, alpha, cost_new\n",
    "        alpha *= 0.5\n",
    "    \n",
    "    print('Line search failed!')\n",
    "    alpha = 0.\n",
    "\n",
    "    return x_trj, u_trj, alpha, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_regu(regu, regu_min, regu_max, alpha):\n",
    "    if alpha == 0.:\n",
    "        return min(regu_max, regu * 10)\n",
    "    if alpha == 1.:\n",
    "        return max(regu_min, regu * 0.1)\n",
    "    return regu\n",
    "\n",
    "def rollout(x0, u_trj, f_dyn):\n",
    "    dim_x = x0.shape[0]\n",
    "    N = u_trj.shape[0]\n",
    "    x_trj = np.zeros((N + 1, dim_x))\n",
    "    x_trj[0, :] = x0\n",
    "    for k in range(N):\n",
    "        x_trj[k+1, :] = f_dyn(x_trj[k, :], u_trj[k, :]).full().flatten()\n",
    "    return x_trj\n",
    "\n",
    "def run_ilqr(params, x0, f_dyn):\n",
    "    N = params.N\n",
    "    dim_u = params.dim_u\n",
    "    u_trj = np.random.randn(N, dim_u) * 0.\n",
    "    x_trj = rollout(x0, u_trj, f_dyn)\n",
    "    # x_trj_hist = [x_trj]\n",
    "    # u_trj_hist = [u_trj]\n",
    "    \n",
    "    regu = params.regu_init\n",
    "    max_regu = params.max_regu\n",
    "    min_regu = params.min_regu\n",
    "    max_iter = params.max_iter\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        traj_cost = trajectory_cost(params, x_trj, u_trj)\n",
    "        # backward pass\n",
    "        K_trj, d_trj, expected_cost_redu = backward_pass(params, x_trj, u_trj, regu)\n",
    "        # forward pass\n",
    "        x_trj_new, u_trj_new, alpha, traj_cost_new = forward_pass(params, x_trj, u_trj, K_trj, d_trj, traj_cost, f_dyn)\n",
    "        x_trj = x_trj_new\n",
    "        u_trj = u_trj_new\n",
    "        regu = update_regu(regu, min_regu, max_regu, alpha)\n",
    "        if alpha > 0 and np.abs(traj_cost_new - traj_cost) < params.cost_redu_tol:\n",
    "            break\n",
    "     \n",
    "    return x_trj, u_trj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PlannerParams:\n",
    "    Q: np.ndarray = np.diag([1., 20., 1., 1.])\n",
    "    R: np.ndarray = np.diag([0.25])\n",
    "    Qf: np.ndarray = 20 * Q\n",
    "    max_iter: int = 200\n",
    "    regu_init: float = 0.001\n",
    "    max_regu: float = 1e4\n",
    "    min_regu: float = 0.001\n",
    "    N : int = 100\n",
    "\n",
    "    cost_redu_tol: float = 1e-5\n",
    "    max_ls_iter: int = 20\n",
    "    \n",
    "    xf: np.ndarray = np.array([0., np.pi, 0., 0.])\n",
    "    uf: np.ndarray = np.array([0.])\n",
    "    \n",
    "    dim_x: int = 4\n",
    "    dim_u: int = 1\n",
    "\n",
    "x0 = np.array([0., 0., 0., 0.])\n",
    "params = PlannerParams()\n",
    "X_opt_ilqr, U_opt_ilqr = run_ilqr(params, x0, f_rk4_cartpole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time = np.arange(N + 1) * dt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axs[0, 0].plot(time, X_opt_ilqr[:, 0], label='ilqr')\n",
    "axs[0, 0].plot(time, X_opt_ca[0, :], label='CasADi')\n",
    "axs[0, 0].set(ylabel='q1 [m]')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].grid()\n",
    "\n",
    "axs[0, 1].plot(time, np.rad2deg(X_opt_ilqr[: ,1]))\n",
    "axs[0, 1].plot(time, np.rad2deg(X_opt_ca[1, :]))\n",
    "axs[0, 1].set(ylabel='q2 [deg]')\n",
    "axs[0, 1].grid()\n",
    " \n",
    "axs[1, 0].plot(time, X_opt_ilqr[:, 2])\n",
    "axs[1, 0].plot(time, X_opt_ca[2, :])\n",
    "axs[1, 0].set(xlabel='Time [s]', ylabel='q3 [m/s]')\n",
    "axs[1, 0].grid()\n",
    "\n",
    "axs[1, 1].plot(time, X_opt_ilqr[:, 3])\n",
    "axs[1, 1].plot(time, X_opt_ca[3, :])\n",
    "axs[1, 1].set(xlabel='Time [s]', ylabel='q4 [rad/s]')\n",
    "axs[1, 1].grid()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
